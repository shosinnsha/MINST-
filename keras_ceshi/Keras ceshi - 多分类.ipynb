{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from kt_utils import *\n",
    "from keras.layers import Conv1D,ZeroPadding1D,MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset_csv():\n",
    "    train_dataset=np.genfromtxt('train.csv', delimiter=',', dtype=np.int32)\n",
    "    train_set_x_orig=train_dataset[1:32001,1:785]\n",
    "    train_set_y_orig=train_dataset[1:32001,0]\n",
    "    \n",
    "    test_set_x_orig=train_dataset[32001:42001,1:785]\n",
    "    test_set_y_orig=train_dataset[32001:42001,0]\n",
    "    \n",
    "    #train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    #test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 32000\n",
      "number of test examples = 10000\n",
      "X_train shape: (32000, 784)\n",
      "Y_train shape: (32000,)\n",
      "X_test shape: (10000, 784)\n",
      "Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset_csv()\n",
    "\n",
    "# Normalize image vectors\n",
    "#X_train = X_train_orig/255.\n",
    "#X_test = X_test_orig/255.\n",
    "X_train = X_train_orig\n",
    "X_test = X_test_orig\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32000, 784)\n",
      "Y_train shape: (32000, 10)\n",
      "X_test shape: (10000, 784)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Y_train = tf.one_hot(Y_train,10)\n",
    "#Y_test = tf.one_hot(Y_test,10)\n",
    "\n",
    "#Y_train = K.one_hot(Y_train, 10)\n",
    "#Y_test = K.one_hot(Y_test, 10)\n",
    "\n",
    "#Y_test = keras.utils.to_categorical(Y_test , 10)\n",
    "\n",
    "Y_train = np.eye(10)[Y_train]\n",
    "Y_test = np.eye(10)[Y_test]\n",
    "\n",
    "#X_train=X_train[:,None]\n",
    "#X_test=X_test[:,None]\n",
    "#Y_train=np.transpose(Y_train)\n",
    "#Y_test=np.transpose(Y_test)\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32000, 784, 1)\n",
      "Y_train shape: (32000, 10)\n",
      "X_test shape: (10000, 784, 1)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train[:,None]\n",
    "X_test=X_test[:,None]\n",
    "X_train=np.swapaxes(X_train,1,2)\n",
    "#Y_train=np.swapaxes(Y_train,0,1)\n",
    "X_test=np.swapaxes(X_test,1,2)\n",
    "#Y_test=np.swapaxes(Y_test,0,1)\n",
    "\n",
    "#Y_train = tf.transpose(Y_train)\n",
    "#Y_test = tf.transpose(Y_test)\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 769, 32)           544       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 769, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 754, 32)           16416     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 754, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 377, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 377, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12064)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3088640   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,108,170\n",
      "Trainable params: 3,108,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 10\n",
    "\n",
    "# 输入图像的维度，此处是mnist图像，因此是28*28\n",
    "#img_rows, img_cols = 28, 28\n",
    "# 卷积层中使用的卷积核的个数\n",
    "nb_filters = 32\n",
    "# 池化层操作的范围\n",
    "pool_size = [2,]\n",
    "# 卷积核的大小\n",
    "kernel_size = [16,]\n",
    "\n",
    "input_shape = (784,1)\n",
    "\n",
    "# 建立序贯模型\n",
    "model = Sequential()\n",
    "\n",
    "# 卷积层，对二维输入进行滑动窗卷积\n",
    "# 当使用该层为第一层时，应提供input_shape参数，在tf模式中，通道维位于第三个位置\n",
    "# border_mode：边界模式，为\"valid\",\"same\"或\"full\"，即图像外的边缘点是补0\n",
    "# 还是补成相同像素，或者是补1\n",
    "\n",
    "model.add(Conv1D(nb_filters, 16 ,\n",
    "                        padding='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 卷积层，激活函数是ReLu\n",
    "model.add(Conv1D(nb_filters, 16))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 池化层，选用Maxpooling，给定pool_size，dropout比例为0.25\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten层，把多维输入进行一维化，常用在卷积层到全连接层的过渡\n",
    "model.add(Flatten())\n",
    "\n",
    "# 包含128个神经元的全连接层，激活函数为ReLu，dropout比例为0.5\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 包含10个神经元的输出层，激活函数为Softmax\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 输出模型的参数信息\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        #plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            #plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 235s 7ms/step - loss: 2.5936 - acc: 0.7574 - val_loss: 0.1527 - val_acc: 0.9540\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 239s 7ms/step - loss: 0.2013 - acc: 0.9400 - val_loss: 0.1066 - val_acc: 0.9650\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 251s 8ms/step - loss: 0.1582 - acc: 0.9503 - val_loss: 0.0969 - val_acc: 0.9689\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 243s 8ms/step - loss: 0.1357 - acc: 0.9582 - val_loss: 0.0844 - val_acc: 0.9742\n",
      "Epoch 5/10\n",
      " 6272/32000 [====>.........................] - ETA: 2:54 - loss: 0.1021 - acc: 0.9702"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8a2ffe48f54a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n\u001b[1;32m---> 10\u001b[1;33m           verbose=1, validation_data=(X_test, Y_test),shuffle=True,callbacks=[history])\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#编译模型\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "#创建一个实例history\n",
    "history = LossHistory()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test),shuffle=True,callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.091495576703\n",
      "Test accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf655470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 按batch计算在某些输入数据上模型的误差\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "# 输出训练好的模型在测试集上的表现\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#绘制acc-loss曲线\n",
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('my_first_kears_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
